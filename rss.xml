<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tech log</title><link>https://mnod.github.io/</link><description>tech log</description><atom:link href="https://mnod.github.io/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2022 &lt;a href="mailto:mnod@example.com"&gt;mnod&lt;/a&gt; </copyright><lastBuildDate>Wed, 17 Aug 2022 13:06:25 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>cognito user pool</title><link>https://mnod.github.io/posts/20220817.html</link><dc:creator>mnod</dc:creator><description>&lt;h3&gt;create user pool&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws cognito-idp create-user-pool --pool-name testpool1 --user-pool-tags 'key=Name,Value=testpool1' --admin-create-user-config 'AllowAdminCreateUserOnly=true' --account-recovery-setting 'RecoveryMechanisms=[{Priority=1,Name=admin_only}]'
aws cognito-idp list-user-pools --max-results 10
aws cognito-idp describe-user-pool --user-pool-id ap-northeast-1_xxxxxxxxx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;remove user pool&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cognito-idp delete-user-pool --user-pool-id ap-northeast-1_xxxxxxxxx
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;create user and set user password&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws cognito-idp list-users --user-pool-id ap-northeast-1_xxxxxxxxx
aws cognito-idp admin-create-user --user-pool-id ap-northeast-1_xxxxxxxxx --username testuser001 --temporary-password temporary_password
aws cognito-idp admin-set-user-password --user-pool-id ap-northeast-1_xxxxxxxxx --username testuser001 --password parmanent_password --permanent
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;create role before import csv&lt;/h3&gt;
&lt;p&gt;create policy json document&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jq . AllowCognitoCloudwatchLogs.policy
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:DescribeLogStreams",
        "logs:PutLogEvents"
      ],
      "Resource": [
        "arn:aws:logs:ap-northeast-1:xxxxxxxxxxxx:log-group:/aws/cognito/*"
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create policy&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws iam create-policy --policy-name AllowCognitoCloudwatchLogs --policy-document file://AllowCognitoCloudwatchLogs.policy
aws iam list-policies --query 'Policies[?PolicyName==`AllowCognitoCloudwatchLogs`]'
aws iam delete-policy --policy-arn arn:aws:iam::xxxxxxxxxxxx:policy/AllowCognitoCloudwatchLogs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create assume role policy document&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jq . assumepolicy.json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "Service": "cognito-idp.amazonaws.com"
      },
      "Action": "sts:AssumeRole"
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create role&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws iam create-role --role-name Import-Cognito-Userpool --assume-role-policy-document file://assumepolicy.json
aws iam list-roles --query 'Roles[?RoleName==`Import-Cognito-Userpool`]'
aws iam attach-role-policy --role-name Import-Cognito-Userpool --policy-arn arn:aws:iam::xxxxxxxxxxxx:policy/AllowCognitoCloudwatchLogs
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;import csv to user pool&lt;/h3&gt;
&lt;p&gt;create csv&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name,given_name,family_name,middle_name,nickname,preferred_username,profile,picture,website,email,email_verified,gender,birthdate,zoneinfo,locale,phone_number,phone_number_verified,address,updated_at,cognito:mfa_enabled,cognito:username
,,,,,,,,,dummy@example.com,true,,,,,,false,,,false,import001
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;import it&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cognito-idp create-user-import-job --user-pool-id ap-northeast-1_xxxxxxxxx --job-name import_job --cloud-watch-logs-role-arn arn:aws:iam::xxxxxxxxxxxx:role/service-role/Cognito-UserImport-Role
curl -v -T "PATH_TO_CSV_FILE" -H "x-amz-server-side-encryption:aws:kms" "PRE_SIGNED_URL"
aws cognito-idp describe-user-import-job --user-pool-id ap-northeast-1_xxxxxxxxx --job-id import-xxxxxxxxxx
aws cognito-idp start-user-import-job --user-pool-id ap-northeast-1_xxxxxxxxx --job-id import-xxxxxxxxxx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;remove unnecessary attributes and set user password&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cognito-idp list-users --user-pool-id ap-northeast-1_xxxxxxxxx
aws cognito-idp admin-delete-user-attributes --user-pool-id ap-northeast-1_xxxxxxxxx --username import001 --user-attribute-names 'email'
aws cognito-idp admin-set-user-password --user-pool-id ap-northeast-1_xxxxxxxxx --username import001 --password permanent_password --permanent
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;disable / enable / delete user&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws cognito-idp list-users --user-pool-id ap-northeast-1_xxxxxxxxx --filter 'username="import001"'
aws cognito-idp admin-disable-user --user-pool-id ap-northeast-1_xxxxxxxxx --username import001
aws cognito-idp admin-enable-user  --user-pool-id ap-northeast-1_xxxxxxxxx --username import001
aws cognito-idp admin-delete-user  --user-pool-id ap-northeast-1_xxxxxxxxx --username import001
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;user pool client&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws cognito-idp list-user-pool-clients --user-pool-id ap-northeast-1_xxxxxxxxx
aws cognito-idp create-user-pool-client --user-pool-id ap-northeast-1_xxxxxxxxx --client-name test-user-pool-client
aws cognito-idp describe-user-pool-client --user-pool-id ap-northeast-1_xxxxxxxxx --client-id xxxxxxxxxxxxxxxxxxxxxxxxx
aws cognito-idp delete-user-pool-client --user-pool-id ap-northeast-1_xxxxxxxxx --client-id xxxxxxxxxxxxxxxxxxxxxxxxx
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;example&lt;/h3&gt;
&lt;p&gt;https://ashura156.hatenablog.com/entry/20180309/1520586674&lt;/p&gt;</description><category>aws</category><guid>https://mnod.github.io/posts/20220817.html</guid><pubDate>Wed, 17 Aug 2022 00:00:00 GMT</pubDate></item><item><title>advanced cloudformation</title><link>https://mnod.github.io/posts/20220810.html</link><dc:creator>mnod</dc:creator><description>&lt;p&gt;create an initial cloudformation stack&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation validate-template --template-body file://template-000.yml
aws cloudformation create-stack --stack-name mystack  --template-body file://mystack-000.yml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;confirm the result&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation describe-stacks --stack-name mystack 
aws cloudformation describe-stack-resources --stack-name mystack 
aws cloudformation describe-stack-events --stack-name mystack
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;change set&lt;/h3&gt;
&lt;p&gt;create change set after editing template file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation create-change-set --stack-name mystack --template-body file://mystack-001.yml --change-set-name mystack-001 --description 'create new Internet Gateway'
aws cloudformation list-change-sets --stack-name mystack 
aws cloudformation describe-change-set --stack-name mystack --change-set-name mystack-001
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;execute the change set&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation execute-change-set --stack-name mystack --change-set-name mystack-001
aws cloudformation list-change-sets --stack-name mystack
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;drift&lt;/h3&gt;
&lt;p&gt;detect stack drift after manual operation&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation detect-stack-drift --stack-name mystack 
aws cloudformation describe-stack-resource-drifts --stack-name mystack
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create change set after editing template file to fit to current resource&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation create-change-set --stack-name mystack --template-body file://mystack-002.yml --change-set-name mystack-002 --description 'reflect manual operation'
aws cloudformation list-change-sets --stack-name mystack 
aws cloudformation describe-change-set --stack-name mystack --change-set-name mystack-002
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;execute the change set&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation execute-change-set --stack-name mystack --change-set-name mystack-002
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;remove change set when the status is false&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aws cloudformation delete-change-set --stack-name mystack --change-set-name mystack-002
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;import&lt;/h3&gt;
&lt;p&gt;create template file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ diff -u template.yml.orig template.yml
+Parameters:
+  ImageId:
+    Type: AWS::EC2::Image::Id
+  InstanceType:
+    Type: String
+  KeyName:
+    Type: AWS::EC2::KeyPair::KeyName
+  SecurityGroupId:
+    Type: AWS::EC2::SecurityGroup::Id
+  SubnetId:
+    Type: AWS::EC2::Subnet::Id
+

+  ## EC2 instance
+  EC2Instance1:
+    Type: AWS::EC2::Instance
+    DeletionPolicy: Retain
+    Properties: 
+      InstanceType: !Ref InstanceType
+      ImageId: !Ref ImageId
+      KeyName: !Ref KeyName
+      NetworkInterfaces: 
+        - DeviceIndex: "0"
+          GroupSet:
+            - !Ref SecurityGroupId
+          SubnetId: !Ref SubnetId
+      BlockDeviceMappings: 
+        - DeviceName: "/dev/xvda"
+          Ebs: 
+            VolumeType: "gp3"
+            VolumeSize: "8"
+      CreditSpecification:
+        CPUCredits: "standard"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create parameter file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jq . parameters.json
[
  {
    "ParameterKey": "ImageId",
    "ParameterValue": "ami-007daaef51c7530e7"
  },
  {
    "ParameterKey": "InstanceType",
    "ParameterValue": "t4g.nano"
  },
  {
    "ParameterKey": "KeyName",
    "ParameterValue": "testkey"
  },
  {
    "ParameterKey": "SecurityGroupId",
    "ParameterValue": "sg-xxxxxxxxxxxxxxxxx"
  },
  {
    "ParameterKey": "SubnetId",
    "ParameterValue": "subnet-xxxxxxxxxxxxxxxxx"
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create a resources-to-import file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ jq . import.json 
[
  {
    "ResourceType": "AWS::EC2::Instance",
    "LogicalResourceId": "EC2Instance1",
    "ResourceIdentifier": {
      "InstanceId": "i-xxxxxxxxxxxxxxxxx"
    }
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create change set for import and execute it&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ aws cloudformation validate-template --template-body file://template.yml
$ aws cloudformation create-change-set --stack-name mystack --change-set-name import-ec2instance --change-set-type IMPORT --resources-to-import file://import.json --template-body file://template.yml --parameters file://parameters.json
$ aws cloudformation describe-change-set --change-set-name import-ec2instance --stack-name mystack
$ aws cloudformation execute-change-set  --change-set-name import-ec2instance --stack-name mystack
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;confirm the result&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ aws cloudformation describe-stacks --stack-name mystack
$ aws cloudformation describe-stack-events --stack-name mystack
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;detect stack drift&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ aws cloudformation detect-stack-drift --stack-name mystack
$ aws cloudformation describe-stack-drift-detection-status --stack-drift-detection-id xxxxxxxxxxxxx-xxxx-xxxx-xxxxxxxxxxx
$ aws cloudformation describe-stack-resource-drifts --stack-name mystack
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If any drift exist, edit stack template to fit to current resource and create and execute change set.&lt;/p&gt;
&lt;p&gt;after that, change deletion policy to &lt;code&gt;Delete&lt;/code&gt; and update stack if needed&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ aws cloudformation update-stack --stack-name mystack --template-body file://template.yml --parameters file://parameters.json
&lt;/code&gt;&lt;/pre&gt;</description><category>aws</category><guid>https://mnod.github.io/posts/20220810.html</guid><pubDate>Wed, 10 Aug 2022 00:00:00 GMT</pubDate></item><item><title>ami</title><link>https://mnod.github.io/posts/20220808.html</link><dc:creator>mnod</dc:creator><description>&lt;h3&gt;create AMI&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 create-image --description 'backup ami of test server' --instance-id i-xxxx --name 'backup ami of test server' --no-reboot
aws ec2 deregister-image --image-id ami-xxxx 
aws ec2 describe-snapshots --owner-id xxxx --query 'Snapshots[?contains(Description, `ami-xxxx`)]'
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;create an instance with AMI&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 run-instances \
--image-id ami-xxxx \
--instance-type t4g.nano \
--key-name testkey \
--security-group-ids sg-xxxx \
--subnet-id subnet-xxxx \
--credit-specification 'CpuCredits=standard' \
--tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=copied_instance}]' \
--associate-public-ip-address
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;delete AMI&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 deregister-image --image-id ami-xxxx 
aws ec2 describe-snapshots --owner-id xxxx --query 'Snapshots[?contains(Description, `ami-xxxx`)].SnapshotId'
aws ec2 delete-snapshot --snapshot-id snap-xxxx
&lt;/code&gt;&lt;/pre&gt;</description><category>aws</category><guid>https://mnod.github.io/posts/20220808.html</guid><pubDate>Mon, 08 Aug 2022 00:00:00 GMT</pubDate></item><item><title>ebs</title><link>https://mnod.github.io/posts/20220807.html</link><dc:creator>mnod</dc:creator><description>&lt;h3&gt;create an EBS volume and attach to an EC2 instance&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 create-volume --availability-zone ap-northeast-1a --volume-type gp3 --size 1 --encrypted --tag-specifications 'ResourceType=volume,Tags=[{Key=Name,Value=test_volume}]'
aws ec2 describe-volumes --volume-id vol-xxxx
aws ec2 attach-volume --device /dev/xvdb --instance-id i-xxxx --volume-id vol-xxxx
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;make partition and make filesystem&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ lsblk
$ sudo parted /dev/nvme1n1 print
$ sudo parted /dev/nvme1n1 mklabel gpt
$ sudo parted /dev/nvme1n1 mkpart home ext4 1MB 100%

$ sudo mkfs -t ext4 /dev/nvme1n1p1
$ sudo tune2fs -L homefs /dev/nvme1n1p1
$ ls -l /dev/disk/by-label/
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;edit /etc/fstab and reboot&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;$ sudo mount /dev/nvme1n1p1 /mnt
$ sudo cp -pri /home/ubuntu /mnt
$ sudo cp -pri /etc/fstab /etc/fstab.000
$ sudo vi /etc/fstab
$ diff /etc/fstab /etc/fstab.000
3d2

aws ec2 reboot-instances --instance-ids i-xxxx --dry-run
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;extend disk size&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 modify-volume --volume-id vol-xxxx --size 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;extend partition and filesystem&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ lsblk
$ sudo growpart /dev/nvme1n1 1

$ df -hT /home
$ sudo resize2fs /dev/nvme1n1p1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;create snapshot&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 describe-snapshots --owner-id xxxx
aws ec2 create-snapshot --volume-id vol-xxxx --description 'test snapshot of homefs' --tag-specifications 'ResourceType=snapshot,Tags=[{Key=Name,Value=homefs}]'
aws ec2 describe-snapshots --owner-id xxxx --filters 'Name=volume-id,Values=vol-xxxx'
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;create new EBS volume from snapshot&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 create-volume --availability-zone ap-northeast-1a --snapshot-id snap-xxxx --volume-type gp3 --encrypted --tag-specifications 'ResourceType=volume,Tags=[{Key=Name,Value=test_volume}]'
aws ec2 describe-volumes --volume-id vol-yyyy
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;attach new volume and detach old volume&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 attach-volume --device /dev/xvdc --instance-id i-xxxx --volume-id vol-yyyy
aws ec2 stop-instances --instance-ids i-xxxx
aws ec2 detach-volume --no-force --instance-id i-xxxx --volume-id vol-xxxx
aws ec2 start-instances --instance-ids i-xxxx
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;delete volume&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 delete-volume --volume-id vol-yyyy
aws ec2 describe-volumes
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;delete snapshot&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;aws ec2 describe-snapshots --owner-id xxxx
aws ec2 delete-snapshot --snapshot-id snap-xxxx
&lt;/code&gt;&lt;/pre&gt;</description><category>aws</category><guid>https://mnod.github.io/posts/20220807.html</guid><pubDate>Sun, 07 Aug 2022 00:00:00 GMT</pubDate></item><item><title>let's encrrypt</title><link>https://mnod.github.io/posts/20220627.html</link><dc:creator>mnod</dc:creator><description>&lt;pre&gt;&lt;code&gt;certbot certonly \
--dry-run \
-d www.example.net \
-m yourname@example.net \
--preferred-challenges dns-01  \
--server https://acme-v02.api.letsencrypt.org/directory \
--manual \
--manual-auth-hook /home/user/work/letsencrypt/dns01-auth.sh \
--manual-cleanup-hook /home/user/work/letsencrypt/dns01-clean.sh \
--post-hook /home/user/work/letsencrypt/post-hook.sh \
--work-dir /home/user/work/letsencrypt/work \
--logs-dir /home/user/work/letsencrypt/logs \
--config-dir /home/user/work/letsencrypt/conf
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;When you run certbot in non-root user, you have to specify --work-dir, --logs-dir, and --config-dir options.  These directories have to be writable with your user.&lt;/li&gt;
&lt;li&gt;You can only publish new certificate file via certbot. Your new certificate file will pushed under config-dir directory. Afterward, you can deploy it with your deploy tool which you like. &lt;/li&gt;
&lt;li&gt;The dns-01 challenge authentication only needs DNS validation and don't need to access via 80/tcp nor web server installation on your server.
When you use dns-01 challenge, you can use your script to update your dns resource to --manual-auth-hook (for authentication) and --manual-cleanup-hook (for cleanup entry).&lt;br&gt;
CERTBOT_DOMAIN varaible is used to show domain name which you want to use. CERTBOT_VALIDATION vaibale is used to show validation code.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;sample script which create validtion entry for aws route53&lt;/p&gt;
&lt;script src="https://gist.github.com/mnod/0ed9ec48287d3a785a1e648911720b37.js?file=dns01-auth.sh"&gt;&lt;/script&gt;

&lt;p&gt;sample script which delete validtion entry for aws route53&lt;/p&gt;
&lt;script src="https://gist.github.com/mnod/0ed9ec48287d3a785a1e648911720b37.js?file=dns01-clean.sh"&gt;&lt;/script&gt;

&lt;pre&gt;&lt;code&gt;certbot renew \
--dry-run \
--post-hook /home/user/work/letsencrypt/post-hook.sh \
--work-dir /home/user/work/letsencrypt/work \
--logs-dir /home/user/work/letsencrypt/logs \
--config-dir /home/user/work/letsencrypt/conf
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Once you get your new certificate, you have to update your certificate periodically.&lt;/li&gt;
&lt;/ul&gt;</description><category>aws</category><category>linux</category><category>openssl</category><guid>https://mnod.github.io/posts/20220627.html</guid><pubDate>Mon, 27 Jun 2022 00:00:00 GMT</pubDate></item><item><title>network time security</title><link>https://mnod.github.io/posts/20220615.html</link><dc:creator>mnod</dc:creator><description>&lt;p&gt;&lt;a href="https://fedoramagazine.org/secure-ntp-with-nts/"&gt;Secure NTP with NTS&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Chrony supports nts since version 4.0. I tried to build nts server and client.&lt;/p&gt;
&lt;h3&gt;server configuration&lt;/h3&gt;
&lt;p&gt;example of chrony 4.2 on ubuntu 22.04 LTS&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server time.facebook.com iburst maxpoll 11
server time.google.com   iburst maxpoll 11
server time.apple.com    iburst maxpoll 11

ntsserverkey /etc/chrony/key.pem
ntsservercert /etc/chrony/crt.pem
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;key.pem and crt.pem are openssl private key and certificate(with intermediate ca certificate) file pair.
The certificate needs to include your fqdn of your nts server.&lt;/p&gt;
&lt;p&gt;When I put key and crt files in a sub directory of /etc/ssl, below error occured.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Could not set credentials : Error while reading file.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In /var/log/syslog, I found audit log of apparmor which shows it denied for chronyd to open the key file.
When I put them in /etc/chrony, I successed to run it.&lt;/p&gt;
&lt;p&gt;Before test from client, you have to open not only 123/udp for NTP but also 4460/tcp for NTS-KE.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ chronyd -Q -t 8 'server mynts.example.com iburst nts'
$ sudo chronyc serverstats
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;client configuration&lt;/h3&gt;
&lt;p&gt;example of chrony 4.0 on Debian 11&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;server mynts.example.com iburst nts
server ptbtime1.ptb.de   iburst nts
server nts.time.nl       iburst nts
server nts.ntp.se        iburst nts

ntstrustedcerts /etc/chrony/cacert.crt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you use selfsigned CA to make your certificate in the nts server, you have to show your own ca certificate file to chrony.conf in ntstrustedcerts.&lt;/p&gt;</description><category>linux</category><category>ntp</category><guid>https://mnod.github.io/posts/20220615.html</guid><pubDate>Wed, 15 Jun 2022 00:00:00 GMT</pubDate></item><item><title>wireguard on raspberryrpi</title><link>https://mnod.github.io/posts/20220614.html</link><dc:creator>mnod</dc:creator><description>&lt;p&gt;I tried to install wireguard with &lt;a href="https://docs.pivpn.io/install/"&gt;pivpn&lt;/a&gt; on 64bit Raspberry pi OS (buster, 4B), but it failed&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat &amp;lt;&amp;lt; END &amp;gt; /tmp/pivpn_options.conf                                                                                                                                           
IPv4dev=xx
install_user=pi
VPN=wireguard
pivpnNET=10.x.x.0
subnetClass=24
ALLOWED_IPS="10.x.x.0/24, 192.168.y.0/24"
pivpnMTU=1420
pivpnPORT=51820
pivpnDNS1=1.1.1.1
pivpnHOST=myname.example.com
pivpnPERSISTENTKEEPALIVE=25
UNATTUPG=1
END

$ curl -L https://install.pivpn.io &amp;gt; /tmp/pivpn_install.sh
$ chmod +x /tmp/pivpn_install.sh
$ /tmp/pivpn_install.sh --noipv6 --unattended /tmp/pivpn_options.conf                                                                                                     


:: wireguard is not a supported VPN protocol on arm64 Debian, only 'openvpn' is
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I was not able to select wireguard in intereractive interface. It select openvpn automatically.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /tmp/pivpn_install.sh --noipv6
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Though I successed it on 32bit Raspberry pi OS (bullseye, 3B+)
It needs NAPT settings to your pi to make a connection from outside wireguard peer.&lt;/p&gt;
&lt;p&gt;I'd like to try it on bookwarm 32bit/64bit when it will be released on the next version of the pi :)&lt;/p&gt;</description><category>failed</category><category>linux</category><category>raspberrypi</category><category>vpn</category><guid>https://mnod.github.io/posts/20220614.html</guid><pubDate>Tue, 14 Jun 2022 00:00:00 GMT</pubDate></item><item><title>WebARENA Indigo API</title><link>https://mnod.github.io/posts/20220521.html</link><dc:creator>mnod</dc:creator><description>&lt;p&gt;&lt;a href="https://web.arena.ne.jp/indigo/"&gt;WebARENA Indigo&lt;/a&gt; is one of the cheapest VPS services in Japan.
It can be controlled via &lt;a href="https://indigo.arena.ne.jp/userapi/"&gt;Rest-API&lt;/a&gt; for some functions.&lt;/p&gt;
&lt;h3&gt;create API key and API secret key&lt;/h3&gt;
&lt;p&gt;Before you use the Rest-API, you have to access controle panel and create API key and API secret key.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;access &lt;a href="https://indigo.arena.ne.jp/"&gt;Indigo ダッシュボード&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;click API鍵の管理 on the left side menu then select API鍵&lt;/li&gt;
&lt;li&gt;click API鍵の作成 on the top of right side&lt;/li&gt;
&lt;li&gt;write down API鍵 and API秘密鍵 &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you'd like to do so, set them as environment variable&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cat &amp;lt;&amp;lt; END &amp;gt; ~/.webarena_secret
&amp;gt; export IndigoApiKey=xxxx
&amp;gt; export IndigoApiPrivateKey=xxxx
&amp;gt; END
$ chmod 600 ~/.webarena_secret
$ cat &amp;lt;&amp;lt; END &amp;gt;&amp;gt; ~/.bashrc
&amp;gt; if [ -f ~/.webarena_secret ]; then
&amp;gt;   . ~/.webarena_secret
&amp;gt; fi
&amp;gt; END
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;create API token&lt;/h3&gt;
&lt;p&gt;After create API key and API secret key, you can create API token.
You need this API token to call other Rest-APIs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;IndigoToken=$(curl -s -X POST \
  https://api.customer.jp/oauth/v1/accesstokens\
  -H 'Content-Type: application/json' \
  -d '{
    "grantType": "client_credentials",
    "clientId": "'${IndigoApiKey}'",
    "clientSecret": "'${IndigoApiPrivateKey}'",
    "code": ""
}' | jq -r .accessToken)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output of this API includes &lt;em&gt;"expiresIn": "3599"&lt;/em&gt;.
I have not confirmed but it would expire in about 3600 seconds.&lt;/p&gt;
&lt;h3&gt;register ssh key&lt;/h3&gt;
&lt;p&gt;ssh key will be installed in ~/.ssh/authorized_keys of login user when the instance will be created.
You can register your own ssh public key instead of create it.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X POST \
  https://api.customer.jp/webarenaIndigo/v1/vm/sshkey \
  -H "Authorization: Bearer ${IndigoToken}" \
  -d '{
   "sshName": "testkey",
   "sshKey": "ssh-rsa xxxx"
}'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I tested to upload "ed25519" public key but I got error message like below.
It seems they don't allow ed25519 keys.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{"success":false,"errorMessage":"Invalid SSH key.","errorCode":"I10034"}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;retrieve information to create instance&lt;/h3&gt;
&lt;p&gt;list ssh keys&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X GET \
  https://api.customer.jp/webarenaIndigo/v1/vm/sshkey \
  -H "Authorization: Bearer ${IndigoToken}" | jq .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;list regions&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;instanceTypeId=$(curl -s -X GET \
  https://api.customer.jp/webarenaIndigo/v1/vm/instancetypes \
  -H "Authorization: Bearer ${IndigoToken}" | jq '.instanceTypes[] | select(.name == "instance") | .id')
curl -s -X GET \
  https://api.customer.jp/webarenaIndigo/v1/vm/getregion?instanceTypeId=${instanceTypeId} \
  -H "Authorization: Bearer ${IndigoToken}" | jq .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;list os&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X GET \
  https://api.customer.jp/webarenaIndigo/v1/vm/oslist?instanceTypeId=${instanceTypeId} \
  -H "Authorization: Bearer ${IndigoToken}" | jq .
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;list instance plans&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X GET \
  'https://api.customer.jp/webarenaIndigo/v1/vm/getinstancespec?instanceTypeId='${instanceTypeId}'&amp;amp;osId=xx' \
  -H "Authorization: Bearer ${IndigoToken}" | jq .
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;create instance&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X POST \
  https://api.customer.jp/webarenaIndigo/v1/vm/createinstance \
  -H "Authorization: Bearer ${IndigoToken}" \
  -d '{
  "sshKeyId": xxxx,
  "regionId": x,
  "osId": xx,
  "instancePlan": x,
  "instanceName": "xxxx"
}'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;list instances&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X GET \
  https://api.customer.jp/webarenaIndigo/v1/vm/getinstancelist \
  -H "Authorization: Bearer ${IndigoToken}"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you create an instance, "instancestatus" will be "OS installation In Progress".
After a while it will become "Stopped". It is a time to start your instance.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X POST \
  https://api.customer.jp/webarenaIndigo/v1/vm/instance/statusupdate \
  -H "Authorization: Bearer ${IndigoToken}" \
  -d '{"instanceId":"xxxx","status":"start"}'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After you start your instance, "instancestatus" will become "Running"&lt;/p&gt;
&lt;h3&gt;firewall&lt;/h3&gt;
&lt;p&gt;The rule is a allow list.
When you create a firewall rule and apply it to your instance, others will be denied.&lt;/p&gt;
&lt;p&gt;create firewall rule&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X POST \
  https://api.customer.jp/webarenaIndigo/v1/nw/createfirewall \
  -H "Authorization: Bearer ${IndigoToken}" \
  -d '{
    "name":"xxxx",
    "inbound":[
        {"type":"Custom","protocol":"TCP","port":"22","source":"x.x.x.x"}
    ],
    "instances":["xxxx"]
}'
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Above rule only allow ssh connection from x.x.x.x. All other inbound connection will be denied.
Since there are no outbound rules, all outbound connection will be allowed&lt;/p&gt;
&lt;p&gt;list firewall&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X GET \
  https://api.customer.jp/webarenaIndigo/v1/nw/getfirewalllist \
  -H "Authorization: Bearer ${IndigoToken}"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;describe a firewall rule&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X GET \
  https://api.customer.jp/webarenaIndigo/v1/nw/gettemplate/xxxx \
  -H "Authorization: Bearer ${IndigoToken}"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;update firewall&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -s -X PUT \
  https://api.customer.jp/webarenaIndigo/v1/nw/updatefirewall \
  -H "Authorization: Bearer ${IndigoToken}" \
  -d '{
    "templateid":"xxxx",
    "name":"xxxx",
    "inbound":[
        {"type":"Custom","protocol":"UDP","port":"123","source":"0.0.0.0"},
        {"type":"Custom","protocol":"TCP","port":"22","source":"x.x.x.x"}
    ],
    "instances":["xxxx"]
}'
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;snapshot&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;stop instance&lt;/li&gt;
&lt;li&gt;create/restore snapshot&lt;/li&gt;
&lt;li&gt;start instance&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When start instance after restore from snapshot, the boot process may stack at GRUB.
You can confirm the situation at QEMU console.&lt;/p&gt;
&lt;p&gt;How to access the console:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;access &lt;a href="https://indigo.arena.ne.jp/"&gt;Indigo ダッシュボード&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;click instance management on the left side menu then select instance.&lt;/li&gt;
&lt;li&gt;click select on the right side of the target instance and select access.&lt;/li&gt;
&lt;li&gt;click "start console"&lt;/li&gt;
&lt;li&gt;If it has stacked at GRUB, click force stop of the left side. After stop, start it again.&lt;/li&gt;
&lt;/ol&gt;</description><category>hosting</category><guid>https://mnod.github.io/posts/20220521.html</guid><pubDate>Sat, 21 May 2022 00:00:00 GMT</pubDate></item><item><title>copy partition of sd card</title><link>https://mnod.github.io/posts/20220328.html</link><dc:creator>mnod</dc:creator><description>&lt;p&gt;dump partition of original sd card&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo parted /dev/sdx print
sudo dd if=/dev/sdx1 of=tablet_sdx1.img bs=4M
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;restore to new sd card&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo parted /dev/sdx print
sudo dd if=tablet_sdx1.img of=/dev/sdx1 bs=4M
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;confirm the size of filesystem&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo mount /dev/sdb1 /media/tmp
df
sudo umount /media/tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;extend the filesystem (if needed)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt install --no-install-recommends fatresize
sudo fatresize -i /dev/sdb1
max=$(expr $(sudo fatresize -i /dev/sdb1 | awk -F: '$1~/Max size/{print $2}') / 1024)
sudo fatresize -s ${max}k /dev/sdb1
sudo fatresize -i /dev/sdb1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;confirm the size of filesystem&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo mount /dev/sdb1 /media/tmp
df
&lt;/code&gt;&lt;/pre&gt;</description><category>linux</category><guid>https://mnod.github.io/posts/20220328.html</guid><pubDate>Mon, 28 Mar 2022 00:00:00 GMT</pubDate></item><item><title>k3s using docker runtime</title><link>https://mnod.github.io/posts/20210629.html</link><dc:creator>mnod</dc:creator><description>&lt;p&gt;&lt;em&gt;install single-node k3s cluster instead of containerd&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I can install with these commands on debian buster arm64 though can not on bullseye.&lt;/p&gt;
&lt;p&gt;at first intall docker&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install ca-certificates curl gnupg lsb-release
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \
$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/null
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io
sudo docker run hello-world
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then install k3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl -sfL https://get.k3s.io | sh -s - --docker
systemctl status k3s
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;uninstall&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/usr/local/bin/k3s-uninstall.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;!--
sudo kubectl get pods --all-namespaces
sudo kubectl get pods --all-namespaces -o wide

sudo kubectl get rs
sudo kubectl scale rs/&lt;rs name&gt; --replicas=0

sudo kubectl exec &lt;pod name&gt; -- &lt;command ...&gt;
sudo kubectl exec -it &lt;pod name&gt; -- /bin/sh
sudo kubectl delete pod &lt;pod name&gt;

sudo kubectl get nodes
sudo kubectl get nodes -o wide
--&gt;

&lt;p&gt;&lt;em&gt;create deployment&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;create yaml file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx-test
        image: nginx-test:latest
        imagePullPolicy: Never
        ports:
        - containerPort: 80
EOF
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create and confirm the deployment&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubectl create -f nginx-deployment.yaml
sudo kubectl get deploy
sudo kubectl get pod
sudo kubectl exec -it &amp;lt;pod name&amp;gt; -- curl localhost
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;create service&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;create yaml file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; nginx-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - protocol: TCP
    targetPort: 80
    port: 80
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;create and confirm the service &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubectl create -f nginx-service.yaml
sudo kubectl get svc
curl x.x.x.x
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;modify service&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubectl apply -f nginx-deployment.yaml
sudo kubectl get svc
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;delete srvice&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubectl delete svc &amp;lt;service name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;delete deployment&lt;/em&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo kubectl delete -f ./nginx-deployment.yaml
&lt;/code&gt;&lt;/pre&gt;</description><category>docker</category><category>linux</category><guid>https://mnod.github.io/posts/20210629.html</guid><pubDate>Wed, 29 Dec 2021 00:00:00 GMT</pubDate></item></channel></rss>