<!DOCTYPE html>
<html prefix="        og: http://ogp.me/ns# article: http://ogp.me/ns/article#     " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<meta name="robots" content="noindex">
<title>Posts about docker | tech log</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../assets/css/custom.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://mnod.github.io/categories/docker.html">
<!--[if lt IE 9]><script src="../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><link rel="alternate" type="application/rss+xml" title="RSS for tag docker" hreflang="en" href="docker.xml">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div id="container">
        
    <header id="header"><h1 id="brand"><a href="../" title="tech log" rel="home">

        <span id="blog-title">tech log</span>
    </a></h1>

        

        
    <nav id="menu"><ul>
<li><a href="../archive.html">Archives</a></li>
                <li><a href="index.html">Tags</a></li>
                <li><a href="../rss.xml">RSS feed</a></li>

    

    
    
    </ul></nav><div class="searchform" role="search">
                
<!-- DuckDuckGo custom search -->
 <form method="get" id="search" action="https://duckduckgo.com/" class="navbar-form pull-left">
 <input type="hidden" name="sites" value="https://mnod.github.io/"><input type="hidden" name="k8" value="#444444"><input type="hidden" name="k9" value="#D51920"><input type="hidden" name="kt" value="h"><input type="text" name="q" maxlength="255" placeholder="Search…" class="span2" style="margin-top: 4px;"><input type="submit" value="DuckDuckGo Search" style="visibility: hidden;">
</form>
 <!-- End of custom search -->

            </div>
    </header><main id="content"><header><h1>Posts about docker</h1>
        <div class="metadata">
            
                <p class="feedlink">
                        
            <a href="docker.xml" hreflang="en" type="application/rss+xml">RSS feed</a>

                </p>

            

        </div>
    </header><div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20210629.html" class="u-url">k3s using docker runtime</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20210629.html" rel="bookmark">
            <time class="published dt-published" datetime="2021-12-29T00:00:00Z" itemprop="datePublished" title="2021-12-29 00:00">2021-12-29 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<!-- https://computingforgeeks.com/install-kubernetes-on-ubuntu-using-k3s/ -->

<p><em>install single-node k3s cluster instead of containerd</em></p>
<p>I can install with these commands on debian buster arm64 though can not on bullseye.</p>
<p>at first intall docker</p>
<pre><code>sudo apt-get update
sudo apt-get install ca-certificates curl gnupg lsb-release
curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/debian \
$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io
sudo docker run hello-world
</code></pre>
<p>then install k3</p>
<pre><code>curl -sfL https://get.k3s.io | sh -s - --docker
systemctl status k3s
</code></pre>
<p><em>uninstall</em></p>
<pre><code>/usr/local/bin/k3s-uninstall.sh
</code></pre>
<!--
sudo kubectl get pods --all-namespaces
sudo kubectl get pods --all-namespaces -o wide

sudo kubectl get rs
sudo kubectl scale rs/<rs name> --replicas=0

sudo kubectl exec <pod name> -- <command ...>
sudo kubectl exec -it <pod name> -- /bin/sh
sudo kubectl delete pod <pod name>

sudo kubectl get nodes
sudo kubectl get nodes -o wide
-->

<p><em>create deployment</em></p>
<p>create yaml file</p>
<pre><code>cat &lt;&lt;EOF &gt; nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx-test
        image: nginx-test:latest
        imagePullPolicy: Never
        ports:
        - containerPort: 80
EOF
</code></pre>
<p>create and confirm the deployment</p>
<pre><code>sudo kubectl create -f nginx-deployment.yaml
sudo kubectl get deploy
sudo kubectl get pod
sudo kubectl exec -it &lt;pod name&gt; -- curl localhost
</code></pre>
<p><em>create service</em></p>
<p>create yaml file</p>
<pre><code>cat &lt;&lt;EOF &gt; nginx-service.yaml
kind: Service
apiVersion: v1
metadata:
  name: my-service
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  - protocol: TCP
    targetPort: 80
    port: 80
</code></pre>
<p>create and confirm the service </p>
<pre><code>sudo kubectl create -f nginx-service.yaml
sudo kubectl get svc
curl x.x.x.x
</code></pre>
<p>modify service</p>
<pre><code>sudo kubectl apply -f nginx-deployment.yaml
sudo kubectl get svc
</code></pre>
<p><em>delete srvice</em></p>
<pre><code>sudo kubectl delete svc &lt;service name&gt;
</code></pre>
<p><em>delete deployment</em></p>
<pre><code>sudo kubectl delete -f ./nginx-deployment.yaml
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20210610.html" class="u-url">squid bump</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20210610.html" rel="bookmark">
            <time class="published dt-published" datetime="2021-06-10T00:00:00Z" itemprop="datePublished" title="2021-06-10 00:00">2021-06-10 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>On debian if you want to analyze or cache the content of the ssl traffic with squid, you have to buid your own squid.
This is a sample to build squid using apt source package.</p>
<h3>build a docker container</h3>
<p>make a dockerfile</p>
<pre><code>FROM debian:buster-slim

WORKDIR /tmp/buildwork
RUN echo 'deb-src http://deb.debian.org/debian buster main' &gt;&gt; /etc/apt/sources.list \
&amp;&amp; apt-get update \
&amp;&amp; apt install --no-install-recommends -y dpkg-dev devscripts build-essential fakeroot libssl-dev libldap2-dev libpam0g-dev libdb-dev cdbs libsasl2-dev debhelper libcppunit-dev libkrb5-dev comerr-dev libcap2-dev libecap3-dev libexpat1-dev libxml2-dev pkg-config libnetfilter-conntrack-dev nettle-dev libgnutls28-dev dh-apparmor ed libdbi-perl libltdl-dev lsb-release libpopt0 logrotate squid-langpack \
&amp;&amp; apt source squid \
&amp;&amp; apt clean \
&amp;&amp; rm -rf /var/lib/apt/lists/*

RUN sed -i.bak -e '/--with-gnutls$/ s/$/ --with-openssl --enable-ssl --enable-ssl-crtd/' squid-4.6/debian/rules \
&amp;&amp; squid-4.6/configure \
&amp;&amp; cd squid-4.6 \
&amp;&amp; debuild -us -uc -b \
&amp;&amp; dpkg -i ../squid_*.deb ../squid-common_*.deb \
&amp;&amp; mkdir -p /var/spool/squid /etc/squid/ssl_cert &amp;&amp; chown proxy:proxy /var/spool/squid \
&amp;&amp; cd /tmp &amp;&amp; rm -rf /tmp/buildwork

VOLUME ["/var/spool/squid"]
EXPOSE 3128

WORKDIR /var/spool/squid
COPY squid.conf /etc/squid/squid.conf
COPY server.crt /etc/squid/ssl_cert/server.crt
COPY server.key /etc/squid/ssl_cert/server.key

CMD chmod 600 /etc/squid/ssl_cert/server.key \
&amp;&amp; if [ ! -f /var/spool/squid/swap.state ]; then squid -z ; fi \
&amp;&amp; if [ ! -d /var/spool/squid/ssl_db ]; then /usr/lib/squid/security_file_certgen -c -s /var/spool/squid/ssl_db -M 20MB ; chown -R proxy. /var/spool/squid/ssl_db ; fi \
&amp;&amp; squid -N
</code></pre>
<p>sample configure file</p>
<pre><code>acl localnet src 192.168.xxx.0/24
acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl CONNECT method CONNECT
acl intermediate_fetching transaction_initiator certificate-fetching
http_access allow intermediate_fetching
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
include /etc/squid/conf.d/*
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/server.crt key=/etc/squid/ssl_cert/server.key
ssl_bump stare all
sslproxy_cert_error allow all
sslcrtd_children 3 startup=1 idle=1
cache_dir ufs /var/spool/squid 100 16 256
coredump_dir /var/spool/squid
refresh_pattern .               129600  33%     525600
dns_nameservers 192.168.xxx.xxx 192.168.xxx.xxx
</code></pre>
<p>If you don't have a CA file and private key for it, you need create them.
When you already have them, I think you can use intermediate CA signed by your own CA.</p>
<pre><code>$ openssl req -x509 -newkey rsa:4096 -sha256 -nodes -keyout server.key -out server.crt -subj "/CN=192.168.xxx.xxx" -days 3650
</code></pre>
<p>build an image</p>
<pre><code>$ docker build --build-arg http_proxy=http://192.168.xxx.xxx:3142/ -t squid:test .
</code></pre>
<p>run a container</p>
<pre><code>$ sudo docker run --rm squid:test squid --version | awk -F: '$1~/options/{print $2}' | sed -e 's/ /\n/g' | grep ssl
'--with-openssl'
'--enable-ssl'
'--enable-ssl-crtd'
$ docker run --rm -p 3128:3128 -v /mnt/squid:/var/spool/squid -d squid:test
</code></pre>
<p>test the address and port</p>
<pre><code>$ curl -D - -s http://192.168.xxx.xxx:3128/ -o /dev/null
</code></pre>
<h3>connecting to HTTPS server</h3>
<pre><code>$ https_proxy=http://192.168.xxx.xxx:3128/ curl -v -k -s https://www.google.com/ -o /dev/null
* Uses proxy env variable https_proxy == 'http://192.168.xxx.xxx:3128/'
*   Trying 192.168.xxx.xxx...
* TCP_NODELAY set
* Connected to 192.168.xxx.xxx (192.168.xxx.xxx) port 3128 (#0)
* allocate connect buffer!
* Establish HTTP proxy tunnel to www.google.com:443
&gt; CONNECT www.google.com:443 HTTP/1.1
&gt; Host: www.google.com:443
&gt; User-Agent: curl/7.61.1
&gt; Proxy-Connection: Keep-Alive
&gt; 
&lt; HTTP/1.1 200 Connection established
&lt; 
* Proxy replied 200 to CONNECT request
* CONNECT phase completed!
:
:
:
* SSL connection using TLSv1.2 / ECDHE-RSA-AES256-GCM-SHA384
* ALPN, server did not agree to a protocol
* Server certificate:
*  subject: C=US; ST=California; L=Mountain View; O=Google LLC; CN=www.google.com
*  start date: May 10 04:04:06 2021 GMT
*  expire date: Aug  2 04:04:05 2021 GMT
*  issuer: CN=192.168.xxx.xxx
*  SSL certificate verify result: self signed certificate in certificate chain (19), continuing anyway.
} [5 bytes data]
&gt; GET / HTTP/1.1
&gt; Host: www.google.com
&gt; User-Agent: curl/7.61.1
&gt; Accept: */*
&gt; 
{ [5 bytes data]
&lt; HTTP/1.1 200 OK
&lt; Date: Wed, 09 Jun 2021 00:22:42 GMT
&lt; Expires: -1
&lt; Cache-Control: private, max-age=0
&lt; Content-Type: text/html; charset=ISO-8859-1
&lt; P3P: CP="This is not a P3P policy! See g.co/p3phelp for more info."
&lt; Server: gws
&lt; X-XSS-Protection: 0
&lt; X-Frame-Options: SAMEORIGIN
&lt; Set-Cookie: 1P_JAR=2021-06-09-00; expires=Fri, 09-Jul-2021 00:22:42 GMT; path=/; domain=.google.com; Secure
&lt; Set-Cookie: NID=216=ptf-d_HIPGOAjnEf-gbmRDmIg3JnEfjqRRnQghOkyFHrdLy5fXGOhydj5jBHonqOlP5WCzPIKX3kIkdizOXCQ13t4moqXwr-UoOWiRXgYaAkx6gyqe03hjM_hwfin5plUuG3NClONGvvFJo5Mqvar7GFYrSFYOMVCXMXvTJ0d4M; expires=Thu, 09-Dec-2021 00:22:42 GMT; path=/; domain=.google.com; HttpOnly
&lt; Alt-Svc: h3-29=":443"; ma=2592000,h3-T051=":443"; ma=2592000,h3-Q050=":443"; ma=2592000,h3-Q046=":443"; ma=2592000,h3-Q043=":443"; ma=2592000,quic=":443"; ma=2592000; v="46,43"
&lt; Accept-Ranges: none
&lt; Vary: Accept-Encoding
&lt; X-Cache: MISS from bd2e0fa8b95e
&lt; X-Cache-Lookup: MISS from bd2e0fa8b95e:3128
&lt; Transfer-Encoding: chunked
&lt; Via: 1.1 bd2e0fa8b95e (squid/4.6)
&lt; Connection: keep-alive
&lt; 
{ [5 bytes data]
* Connection #0 to host 192.168.xxx.xxx left intact
</code></pre>
<p>sample log of other connections</p>
<pre><code>1622798061.167    833 192.168.xxx.xxx NONE/200 0 CONNECT dl.fedoraproject.org:443 - HIER_DIRECT/38.145.60.22 -
1622798061.539    260 192.168.xxx.xxx TCP_MISS/200 16108 GET https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm - HIER_DIRECT/38.145.60.22 application/x-rpm
</code></pre>
<pre><code>1622798109.029    496 192.168.xxx.xxx NONE/200 0 CONNECT dl.fedoraproject.org:443 - HIER_DIRECT/38.145.60.22 -
1622798109.130      1 192.168.xxx.xxx TCP_MEM_HIT/200 16115 GET https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm - HIER_NONE/- application/x-rpm
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20210608.html" class="u-url">squid nobump</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20210608.html" rel="bookmark">
            <time class="published dt-published" datetime="2021-06-08T00:00:00Z" itemprop="datePublished" title="2021-06-08 00:00">2021-06-08 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>The squid packages of debian doesn not support <a href="https://wiki.squid-cache.org/Features/SslBump">sslbump</a>.
It only redirects ssl traffic. We can not analyze or cache the content of the ssl traffic.</p>
<h3>build a docker container</h3>
<p>make a dockerfile</p>
<pre><code>FROM debian:buster-slim

RUN apt-get update \
&amp;&amp; apt install -y squid \
s&amp;&amp; apt clean \
&amp;&amp; rm -rf /var/lib/apt/lists/*

VOLUME ["/var/spool/squid"]
EXPOSE 3128

WORKDIR /var/spool/squid
COPY squid.conf /etc/squid/squid.conf

CMD if [ ! -f /var/spool/squid/swap.state ]; then squid -z ; sleep 2; fi \
&amp;&amp; squid -N
</code></pre>
<p>sample configure file</p>
<pre><code>acl localnet src 192.168.xxx.0/24
acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
include /etc/squid/conf.d/*
http_access allow localnet
http_access allow localhost
http_access deny all
http_port 3128
cache_dir ufs /var/spool/squid 100 16 256
coredump_dir /var/spool/squid
refresh_pattern .               129600  33%     525600
dns_nameservers 192.168.xxx.xxx 192.168.xxx.xxx
</code></pre>
<p>build an image</p>
<pre><code>$ docker build --build-arg http_proxy=http://192.168.xxx.xxx:3142/ -t squid:test .
</code></pre>
<p>run a container</p>
<pre><code>$ docker run --rm squid:test squid --version | awk -F: '$1~/options/{print $2}' | sed -e 's/ /\n/g' | grep ssl
(result will be nothing)
$ docker run --rm -p 3128:3128 -v /mnt/squid:/var/spool/squid -d squid:test
</code></pre>
<p>test the address and port</p>
<pre><code>$ curl -D - -s http://192.168.xxx.xxx:3128/ -o /dev/null
</code></pre>
<h3>connecting to HTTP server</h3>
<p>without proxy</p>
<pre><code>$ curl -v -s http://ftp.yz.yamagata-u.ac.jp/pub/linux/centos/5.11/readme -o /dev/null
*   Trying 2001:df0:25e:e100::3...
* TCP_NODELAY set
* Connected to ftp.yz.yamagata-u.ac.jp (2001:df0:25e:e100::3) port 80 (#0)
&gt; GET /pub/linux/centos/5.11/readme HTTP/1.1
&gt; Host: ftp.yz.yamagata-u.ac.jp
&gt; User-Agent: curl/7.64.0
&gt; Accept: */*
&gt;
&lt; HTTP/1.1 200 OK
&lt; Date: Mon, 07 Jun 2021 00:59:01 GMT
&lt; Server: Apache/2.4.46 (Unix) OpenSSL/1.1.1k
&lt; Upgrade: h2,h2c
&lt; Connection: Upgrade
&lt; Last-Modified: Mon, 03 Apr 2017 11:34:28 GMT
&lt; ETag: "14b-54c418ac05900"
&lt; Accept-Ranges: bytes
&lt; Content-Length: 331
&lt;
{ [331 bytes data]
* Connection #0 to host ftp.yz.yamagata-u.ac.jp left intact
</code></pre>
<p>with proxy</p>
<pre><code>$ http_proxy=http://192.168.xxx.xxx:3128/ curl -v -s http://ftp.yz.yamagata-u.ac.jp/pub/linux/centos/5.11/readme -o /dev/null
* Uses proxy env variable http_proxy == 'http://192.168.xxx.xxx:3128/'
*   Trying 192.168.xxx.xxx...
* TCP_NODELAY set
* Connected to 192.168.xxx.xxx (192.168.xxx.xxx) port 3128 (#0)
&gt; GET http://ftp.yz.yamagata-u.ac.jp/pub/linux/centos/5.11/readme HTTP/1.1
&gt; Host: ftp.yz.yamagata-u.ac.jp
&gt; User-Agent: curl/7.64.0
&gt; Accept: */*
&gt; Proxy-Connection: Keep-Alive
&gt;
&lt; HTTP/1.1 200 OK
&lt; Date: Mon, 07 Jun 2021 00:58:26 GMT
&lt; Server: Apache/2.4.46 (Unix) OpenSSL/1.1.1k
&lt; Last-Modified: Mon, 03 Apr 2017 11:34:28 GMT
&lt; ETag: "14b-54c418ac05900"
&lt; Accept-Ranges: bytes
&lt; Content-Length: 331
&lt; X-Cache: MISS from e3b21f81fdd2
&lt; X-Cache-Lookup: MISS from e3b21f81fdd2:3128
&lt; Via: 1.1 e3b21f81fdd2 (squid/4.6)
&lt; Connection: keep-alive
&lt;
{ [331 bytes data]
* Connection #0 to host 192.168.xxx.xxx left intact
</code></pre>
<p>when cache hit</p>
<pre><code>&lt; Age: 358
&lt; X-Cache: HIT from e3b21f81fdd2
&lt; X-Cache-Lookup: HIT from e3b21f81fdd2:3128
</code></pre>
<p>squid log</p>
<pre><code>$ docker exec xxxxxxxxxxxx tail /var/log/squid/access.log
:
1623026732.001    265 192.168.xxx.xxx TCP_MISS/200 685 GET http://ftp.yz.yamagata-u.ac.jp/pub/linux/centos/5.11/readme - HIER_DIRECT/133.24.248.17 -
1623027089.025      0 192.168.xxx.xxx TCP_MEM_HIT/200 693 GET http://ftp.yz.yamagata-u.ac.jp/pub/linux/centos/5.11/readme - HIER_NONE/- -
</code></pre>
<h3>connecting to HTTPS server</h3>
<p>without proxy</p>
<pre><code>$ curl -v -k -s https://www.google.com/ -o /dev/null 
*   Trying 142.250.196.132...
* TCP_NODELAY set
* Connected to www.google.com (142.250.196.132) port 443 (#0)
:
</code></pre>
<p>with proxy</p>
<pre><code>$ https_proxy=http://192.168.xxx.xxx:3128/ curl -v -k -s https://www.google.com/ -o /dev/null 
* Uses proxy env variable https_proxy == 'http://192.168.xxx.xxx:3128/'
*   Trying 192.168.xxx.xxx...
* TCP_NODELAY set
* Connected to 192.168.xxx.xxx (192.168.xxx.xxx) port xxxxx (#0)
* allocate connect buffer!
* Establish HTTP proxy tunnel to www.google.com:443
&gt; CONNECT www.google.com:443 HTTP/1.1
&gt; Host: www.google.com:443
&gt; User-Agent: curl/7.61.1
&gt; Proxy-Connection: Keep-Alive
&gt; 
&lt; HTTP/1.1 200 Connection established
&lt; 
* Proxy replied 200 to CONNECT request
* CONNECT phase completed!
:
</code></pre>
<p>squid log. The ssl connection is just tunneled.</p>
<pre><code>$ sudo docker exec xxxxxxxxxxxx tail /var/log/squid/access.log
:
1622950724.481    170 192.168.xxx.xxx TCP_TUNNEL/200 18439 CONNECT www.google.com:443 - HIER_DIRECT/172.217.175.4 -
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20210605.html" class="u-url">devpi-server</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20210605.html" rel="bookmark">
            <time class="published dt-published" datetime="2021-06-05T00:00:00Z" itemprop="datePublished" title="2021-06-05 00:00">2021-06-05 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p><a href="https://pypi.org/project/devpi-server/">devpi-server</a> is a server for private package indexes and PyPI caching.</p>
<h3>build a docker container</h3>
<p>make a dockerfile</p>
<pre><code>FROM debian:buster-slim

ENV DEBIAN_FRONTEND noninteractive
RUN apt update &amp;&amp; \
    apt install --no-install-recommends -y \
    python3-pip python3-pip python3-setuptools python3-dev build-essential libffi-dev &amp;&amp; \
    pip3 install devpi-server

EXPOSE 3141
VOLUME ["/var/cache/devpi"]

CMD chmod 777 /var/cache/devpi &amp;&amp; \
    devpi-server \
        --serverdir /var/cache/devpi \
        --host 0.0.0.0 --port 3141
</code></pre>
<p>build an image</p>
<pre><code>$ sudo docker build --build-arg http_proxy=http://192.168.xxx.xxx:3142/ -t devpi-server:buster-slim .
$ sudo docker tag devpi-server:buster-slim devpi-server:latest
</code></pre>
<p>run a container</p>
<pre><code>$ sudo docker run --rm -d -p 3141:3141 -v /mnt/devpi:/var/cache/devpi devpi-server:latest
</code></pre>
<p>test the address and port</p>
<pre><code>$ curl http://192.168.xxx.xxx:3141/
</code></pre>
<h3>how to use devpi-server</h3>
<p>specify it in a command line</p>
<pre><code>$ pip3 install --trusted-host 192.168.xxx.xxx --index-url http://192.168.xxx.xxx:3141/root/pypi matplotlib
</code></pre>
<p>or </p>
<pre><code>$ PIP_TRUSTED_HOST=192.168.xxx.xxx PIP_INDEX_URL=http://192.168.xxx.xxx:3141/root/pypi pip3 install matplotlib
</code></pre>
<p>for docker build, write below in a Dockerfile</p>
<pre><code>ARG PIP_TRUSTED_HOST
ARG PIP_INDEX_URL
</code></pre>
<p>then specify devpi-server at build-arg parameter in docker run command line.</p>
<pre><code>$ docker build --build-arg PIP_TRUSTED_HOST=192.168.xxx.xxx --build-arg PIP_INDEX_URL=http://192.168.xxx.xxx:3141/root/pypi -t imagename .
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20200926.html" class="u-url">docker on raspberrypi</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20200926.html" rel="bookmark">
            <time class="published dt-published" datetime="2020-09-26T00:00:00Z" itemprop="datePublished" title="2020-09-26 00:00">2020-09-26 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Install docker on <a href="https://www.raspberrypi.org/forums/viewtopic.php?f=117&amp;t=275370">Raspberry Pi OS (64bit) beta test version</a>
We can download the iso images from https://downloads.raspberrypi.org/raspios_arm64/images/</p>
<p>Also we can use torrent to download them</p>
<p>make a script to stop transmission when download finished (in this case, the script name is stop_torrent.sh)</p>
<pre><code>sleep 10
kill $(ps -ef | grep transmission | grep -v grep | awk '{print $2}')
</code></pre>
<p>then start download</p>
<pre><code>transmissIon-cli --download-dir (fullpath) --uplimit (kbps) --downlimit (kbps) --encryption-required --finish (fullpath)/stop_torrent.sh https://(fqdn)/(path)/(filename).torrent
</code></pre>
<p><a href="https://docs.docker.com/engine/install/debian/">How to install</a></p>
<pre><code>$ curl -fsSL https://get.docker.com -o get-docker.sh
$ sudo sh get-docker.sh --dry-run
$ sudo sh get-docker.sh
$ systemctl is-active docker
$ systemctl is-enabled docker
$ sudo docker version
</code></pre>
<p>change the docker root directory where we store the images and containers.</p>
<pre><code>$ sudo docker info | grep Root
$ sudo systemctl stop docker
$ sudo mv /var/lib/docker /path/to/
$ sudo ln -s /path/to/docker /var/lib/docker
$ sudo systemctl start docker
$ sudo docker run --rm hello-world
</code></pre>
<p>confirm the result</p>
<pre><code>$ sudo docker run --rm -it alpine
/ #
/ # uptime
 03:17:44 up 1 day,  2:47,  load average: 0.02, 0.05, 0.01
/ #
/ # uname -a
Linux 4db177a44a14 5.4.42-v8+ #1319 SMP PREEMPT Wed May 20 14:18:56 BST 2020 aarch64 Linux
/ #
/ # free -m
              total        used        free      shared  buff/cache   available
Mem:           7816         315        6339           2        1161        7460
Swap:          8191           0        8191
</code></pre>
<p>install docker-compose</p>
<pre><code>$ http_proxy=http://192.168.xxx.xxx:3142/ sudo -E apt install libffi-dev libssl-dev
$ sudo pip3 install docker-compose
$ pip3 show docker-compose
$ docker-compose version
</code></pre>
<p>commands of docker-compose</p>
<pre><code>config # Validate and view the Compose file
ps # List containers
images # List images
build # (Re)Build services
create # Create services
up # Create and start containers
start # Start services
stop # Stop services
rm -f # Remove stopped containers
down # Stop and remove containers
version # Show version information
help # Show help messages
</code></pre>
<p>When update docker-compose.yml, no need to rebuild the image.</p>
<pre><code>docker-compose up -d
</code></pre>
<p>When update Dockerfile or edit any source codes, need to rebuild the image.</p>
<pre><code>docker-compose build
docker-compose up -d
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20200516.html" class="u-url">terraform docker container</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20200516.html" rel="bookmark">
            <time class="published dt-published" datetime="2020-05-16T00:00:00Z" itemprop="datePublished" title="2020-05-16 00:00">2020-05-16 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>Dockerfile</p>
<pre><code>From centos:centos8

ARG VERSION=0.12.25
RUN yum install -y unzip python2-pip openssh-clients &amp;&amp; \
    yum clean all &amp;&amp; \
    curl -s https://releases.hashicorp.com/terraform/${VERSION}/terraform_${VERSION}_linux_amd64.zip -o terraform.zip &amp;&amp; \
    unzip terraform.zip &amp;&amp; \
    rm terraform.zip &amp;&amp; \
    mv terraform /usr/local/bin &amp;&amp; \
    pip2 install ansible boto boto3 awscli &amp;&amp; \
    ln -s /usr/bin/python2.7 /usr/bin/python &amp;&amp; \
    mkdir /tmp/terraform &amp;&amp; \
    useradd -m docker

VOLUME ["/tmp/terraform"]
USER "docker"
WORKDIR "/tmp/terraform"
CMD ["/bin/bash"]
</code></pre>
<p>build an image</p>
<pre><code>$ sudo docker build --build-arg VERSION=0.12.25 -t terraform:0.12.25 .
$ sudo docker tag terraform:0.12.25 terraform:latest
</code></pre>
<p>test the image</p>
<pre><code>$ sudo docker run -v /mylocal/terraform:/tmp/terraform --rm -it terraform:latest terraform --version
$ sudo docker run -v /mylocal/terraform:/tmp/terraform --rm -it terraform:latest ansible --version
$ sudo docker run -v /mylocal/terraform:/tmp/terraform --rm -it terraform:latest bash
</code></pre>
<p>create variable file /mydir/credentials </p>
<pre><code>AWS_ACCESS_KEY_ID=xxxx
AWS_SECRET_ACCESS_KEY=xxxx
AWS_DEFAULT_REGION=xxxx
</code></pre>
<p>create wrapper script infradeploy.sh</p>
<pre><code>docker run -v /mylocal/terraform:/tmp/terraform --env-file /mydir/credentials --rm -it terraform:latest $*
</code></pre>
<p>test terraform and ansible work</p>
<pre><code>$ sudo sh infradeploy.sh terraform show
$ sudo sh infradeploy.sh ./ec2.py --list
$ sudo sh infradeploy.sh ansible -i ec2.py -u admin ec2 -m ping --private-key id_rsa.mykey
$ sudo sh infradeploy.sh ansible-playbook --check -e @extravars.json playbook.yml
</code></pre>
<p>As described at <a href="https://docs.ansible.com/ansible/latest/user_guide/intro_dynamic_inventory.html">this site</a> we can use ec2.py and ec2.ini(optional) for dynamic inventory
When I ran ec2.py I got <code>ImportError: No module named ansible.module_utils</code> in the case I installed ansible from ubuntu repository.
It seems ansible should be installed with pip if you want to use ec2.py</p>
<p>playbook sample</p>
<pre><code>- name: test playbook
  hosts: tag_Name_tagname
  remote_user: admin
  become: yes
  vars:
    ansible_ssh_private_key_file: "./id_rsa.mykey"
  tasks:
    - name: install some packages
      apt:
        name: ['make','screen']
        state: present
        install_recommends: no
      when: ansible_pkg_mgr == 'apt'
      tags: packages

    - name: create a directory
      file:
        path: /my/direcoty
        state: directory
        owner: admin
        mode: '0755'

$ sudo sh infradeploy.sh ansible-playbook --check --diff -i ec2.py playbook.yml
$ sudo sh infradeploy.sh ansible-playbook --diff -i ec2.py playbook.yml
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20200315.html" class="u-url">apt-cacher-ng</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20200315.html" rel="bookmark">
            <time class="published dt-published" datetime="2020-03-15T00:00:00Z" itemprop="datePublished" title="2020-03-15 00:00">2020-03-15 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>make a dockerfile</p>
<pre><code>$ cat Dockerfile
FROM debian:buster

RUN apt-get update \
&amp;&amp; apt-get install -y --no-install-recommends apt-cacher-ng \
&amp;&amp; apt-get clean \
&amp;&amp; rm -rf /var/lib/apt/lists/*

VOLUME ["/var/cache/apt-cacher-ng"]
EXPOSE 3142

CMD chmod 777 /var/cache/apt-cacher-ng \
&amp;&amp; /etc/init.d/apt-cacher-ng start \
&amp;&amp; tail -f /var/log/apt-cacher-ng/*
</code></pre>
<p>build an image</p>
<pre><code>$ sudo docker build -t apt-cacher-ng:buster . | tee build.log
$ sudo docker tag apt-cacher-ng:buster apt-cacher-ng:latest
</code></pre>
<p>run a container</p>
<pre><code>$ sudo docker run --rm -d -p 3142:3142 -v /mnt/apt-cacher-ng:/var/cache/apt-cacher-ng apt-cacher-ng:latest
</code></pre>
<p>test the address and port </p>
<pre><code>$ curl 192.168.xxx.xxx:3142
</code></pre>
<p><em>how to use the cache server</em></p>
<p>specify it in a config file</p>
<pre><code>$ cat &lt;&lt; END | sudo tee /etc/apt/apt.conf.d/01proxy
&gt; Acquire::http::Proxy "http://192.168.xxx.xxx:3142/";
&gt; END
</code></pre>
<p>specify it in command line</p>
<pre><code>$ http_proxy=http://192.168.xxx.xxx:3142/ sudo -E apt-get install xxxx
</code></pre>
<p>or</p>
<pre><code>$ sudo su -
# http_proxy=http://192.168.xxx.xxx:3142/ apt-get install xxxx
</code></pre>
<p>for docker build</p>
<pre><code>$ sudo docker build --build-arg http_proxy=http://192.168.xxx.xxx:3142/ -t imagename:tagname . | tee build.log
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20161001.html" class="u-url">docker life cycle</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20161001.html" rel="bookmark">
            <time class="published dt-published" datetime="2016-10-01T00:00:00Z" itemprop="datePublished" title="2016-10-01 00:00">2016-10-01 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>ライフサイクルをざっと。</p>
<p>dockerデーモンの起動と動作確認。ubuntuの場合。</p>
<pre><code>$ sudo service docker status
$ sudo service docker start
$ sudo docker run --rm hello-world
</code></pre>
<p>リポジトリに登録されているイメージを取得する。</p>
<pre><code>$ sudo docker pull debian:latest
Pulling repository debian
6845b83c79fb: Download complete
575489a51992: Download complete
Status: Downloaded newer image for debian:latest
$ 
$ sudo docker images debian
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
debian              latest              6845b83c79fb        13 days ago         125.1 MB
$
</code></pre>
<p>コンテナを作成して実行。コンソール接続してbashを実行する例。</p>
<pre><code>$ sudo docker run -it debian:latest /bin/bash
root@06e1a850e923:/# 
root@06e1a850e923:/# w
 22:20:47 up 29 days, 14:32,  0 users,  load average: 0.36, 0.29, 0.24
USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT
root@06e1a850e923:/#
root@06e1a850e923:/# uname -a
Linux 06e1a850e923 3.13.0-63-generic #103-Ubuntu SMP Fri Aug 14 21:42:59 UTC 2015 x86_64 GNU/Linux
root@06e1a850e923:/#
root@06e1a850e923:/# cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 8 (jessie)"
NAME="Debian GNU/Linux"
VERSION_ID="8"
VERSION="8 (jessie)"
ID=debian
HOME_URL="http://www.debian.org/"
SUPPORT_URL="http://www.debian.org/support/"
BUG_REPORT_URL="https://bugs.debian.org/"
root@06e1a850e923:/#
</code></pre>
<p>コンソール接続したコンテナから一旦切断する例。</p>
<pre><code>root@xxxxxxxxxxxx:/# [Ctl+p]-[Ctl+q]
$ 
$ sudo docker ps | grep debian
xxxxxxxxxxxx        debian:latest       "/bin/bash"         About a minute ago   Up About a minute                       berserk_mayer
$
</code></pre>
<p>再接続する例。</p>
<pre><code>$ sudo docker attach xxxxxxxxxxxx
root@xxxxxxxxxxxx:/#
</code></pre>
<p>コンテナを終了する例。</p>
<pre><code>root@06e1a850e923:/# exit
exit
$
</code></pre>
<p>終了したコンテナを再起動する例。</p>
<pre><code>$ sudo docker ps -a | grep debian
xxxxxxxxxxxx        debian:latest            "/bin/bash"            13 minutes ago      Exited (0) 13 seconds ago                                          berserk_mayer
$
$ sudo docker start -i xxxxxxxxxxxx
root@xxxxxxxxxxxx:/# 
root@xxxxxxxxxxxx:/# exit
exit
$
</code></pre>
<p>コンテナの状態確認。</p>
<pre><code>$ sudo docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
$ 
$ sudo docker ps -a | grep debian
06e1a850e923        debian:latest            "/bin/bash"            2 minutes ago       Exited (0) 47 seconds ago                                      evil_kowalevski

$
</code></pre>
<p>copy file from/to docker container</p>
<pre><code>$ sudo docker cp xxxxxxxxxxxx:/dirname/filename destination
$ sudo docker cp source xxxxxxxxxxxx:/dirname/filename
</code></pre>
<p>コンテナの削除。</p>
<pre><code>$ sudo docker rm 06e1a850e923
06e1a850e923
$ 
$ sudo docker ps -a | grep debian
$
</code></pre>
<p>イメージの削除。</p>
<pre><code>$ sudo docker rmi debian:latest
Untagged: debian:latest
Deleted: 6845b83c79fb642ed6af06cceaca042e155717ca8eb0b5cffa9c43f1f7f70348
Deleted: 575489a51992d5d30976ff5ba7f7eabdc134acfb51c79ff48883089009594e64
$
$ sudo docker images debian
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
$
</code></pre>
<p>dockerイメージの作成</p>
<pre><code>$ mkdir project &amp;&amp; cd project
$ 
$ vi Dockerfile
$ 
$ sudo docker build -t imagename:tagname . | tee build.log
$ 
$ sudo docker images imagename
$
</code></pre>
<p>When you want to use proxy, use --build-arg option like bellow</p>
<pre><code>$ sudo docker build --build-arg http_proxy=http://192.168.xxx.xxx:3142/ -t imagename:tagname . | tee build.log
</code></pre>
<p>When new image name is <none>, then rename it as below</none></p>
<pre><code>$ sudo docker tag xxxxxxxxxxxx imagename:tagname
$ 
$ sudo docker images imagename
</code></pre>
<p>不要なイメージの一括削除</p>
<pre><code>sudo docker images | awk '$1~/&lt;none&gt;/ {print}'
sudo docker images | awk '$1~/&lt;none&gt;/ {print $3}' | xargs sudo docker rmi
</code></pre>
<p>使用するdockerfileの簡単な例。</p>
<pre><code>From debian:latest
RUN apt-get update &amp;&amp; apt-get install -y \
    screen \
    openssl \
    vim \
   make \
&amp;&amp; apt-get clean \
&amp;&amp; rm -rf /var/lib/apt/lists/*
</code></pre>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/20160925.html" class="u-url">arukas</a></h1>
        <div class="metadata">
            <!-- <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                mnod
            </span></p> -->
            <p class="dateline">
            <a href="../posts/20160925.html" rel="bookmark">
            <time class="published dt-published" datetime="2016-09-25T00:00:00Z" itemprop="datePublished" title="2016-09-25 00:00">2016-09-25 00:00</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<p>2019/10追記</p>
<p><a href="https://arukas.io/updates/20190930-terminate-of-service/">2020/1/31でのサービス終了</a>が発表されました。すでに新規アカウントの申し込みは終了しています。
無料で使える範囲での活用方法を自分の中で見いだしたところでしたので、とても残念です。
大手サービスプロバイダなのに、2018/03 から始まったサービスが 2020/01 で終了してしまうというのは、あまりに早すぎると感じます。利用者が相当少なかったのでしょうか。</p>
<p>2018/04追記</p>
<p>2018/03下旬からサービスインとなっています。βテストの時との違いや気づいた点を記載します。</p>
<ul>
<li>利用するには、アカウント作成(招待制)とクレジット情報の登録が必要です。
(無料のプランしか使う予定が無くてもクレジット情報が必要なようです。)</li>
<li>転送量は無料。当初の予告どおり、無料で使えるFreeプランもあります。
(Freeプランでは0.1vcpu、メインメモリ128MB、同時に作成しておけるコンテナは一つだけ、実行できるのも一つだけ。)</li>
<li>ドメイン名にtokyoと入っていますが、自分が試したときはIPアドレスは大阪方面のものと判定されました。
(βを使い始めた頃は東京方面のアドレスと判定されましたが、以後どうなったのか確認してません)</li>
<li>コントロールパネルのコンテナ作成画面は、利用するプランの選択肢がある以外は、βの時と同じに見えます。</li>
</ul>
<p>自分にとって「東京(のアドレス)で(無料で)使えるサーバ」というのが、非常に価値が大きかったので、ちょっと残念な感じもあります。
いずれにせよ無料で使えるプランがあるのはありがたいですので、
いろいろ制限がある中、どんなことがどこまでできるのか、試してみたいと思ってます。</p>
<p>2017/08追記</p>
<p>2017/07末をもってβテストが終わりました。そのまま正式サービスに移行するのではなく、一旦サービスを止めたようです。
正式サービスの開始時期は今のところ未定とのことです。</p>
<p>追記ここまで。</p>
<p><a href="https://arukas.io/">arukas</a>は、コンテナ技術の<a href="https://www.docker.com/">docker</a>を利用したホスティングサービスです。</p>
<p>逆から読むと、sakura。<a href="http://vps.sakura.ad.jp/sp/">さくらのVPS</a>でおなじみの、<a href="https://www.sakura.ad.jp">さくらインターネット</a>のサービスです。
無料で利用することができるオープンβテストが4月末ごろから9月末までの予定で行われており、間もなく正式リリースとなるものと思われます。
正式リリースした後も無料で利用できるプランが設定されるようです。</p>
<p>arukasでは、<a href="https://hub.docker.com/">Docker Hub</a>の<a href="https://hub.docker.com/explore/">パブリックレポジトリ</a>にアップロードされたコンテナを登録して、起動することができます。
Docker Hubには沢山のレポジトリが登録されていますが、自分で作成・登録することもできます。
無いものは自分で作ってしまえばいいので、実際には、どんなコンテナでも動かすことができます。</p>
<p>dockerの利点は、コンテナの作成・起動・終了・削除が迅速にできることで、これはそのままarukasにも当てはまります。
ベータテストのためなのか、以下の制限があります。</p>
<ul>
<li>データ永続化の仕組みがないので、再起動するとデータが消える。</li>
<li>定期的(週に一度くらい?)に再起動される。</li>
</ul>
<p>そのため永続的に使いたいデータは、外部に置く必要があります。
正式リリース後には変更される可能性もあるかもしれません。</p>
<p>URLとポートを指定すれば、起動したコンテナに外部から接続することができます。この場合は通信プロトコルはhttp(s)に限りません。</p>
<p>同じ内容のものを複数のコンテナで動かすことができますが、この場合、エンドポイントという与えられたurlにhttps接続することで、各コンテナにロードバランスして接続させることができます。(バランスさせるアルゴリズムなどは公開されていないようです。)
この時、tlsにより通信内容は暗号化されます。自分で証明書を準備する必要がありません。ただし、プロトコルはhttpに限られます。</p>
</div>
    </div>
    </article>
</div>







        </main><footer id="footer"><p>Contents © 2021         <a href="mailto:mnod@example.com">mnod</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
            
        </footer>
</div>
    
            <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
